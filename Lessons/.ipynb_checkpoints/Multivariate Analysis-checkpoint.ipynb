{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate analysis: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/media/overview/tdsp-lifecycle2.png \"Data Science Lifecycle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting sources: \n",
    "- https://learn.datacamp.com/courses/machine-learning-with-tree-based-models-in-python\n",
    "- https://www.datacamp.com/community/tutorials/decision-tree-classification-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that we can uncover correlations by using bivariate analyis. This also raises the question: If we extract information from multiple columns (Multivariate analysis), could we use these correlations to calculate/predict the value of a column for rows that do not yet have a value?\n",
    "\n",
    "For example:\n",
    "- Can we calculate if a customer will churn (= We lose the customer)?\n",
    "- Can we calculate if a customer would use a certain product? (Product recommendation)\n",
    "- Can we calculate if a mail is spam or not?\n",
    "- Can we calculate if a financial transaction is fraudulent or not?\n",
    "- Can we calculate if a customer will be able to pay back their loan or not?\n",
    "- Can we calculate the price people are willing to pay for a house?\n",
    "- Can we calculate the salary a student will earn in the future?\n",
    "- ...\n",
    "\n",
    "Just as we used math/statistics to support to explore the data one column at a time (Univariate) and per combination of two columns (Bivariate analysis), we will use machine learning algorithms to extract information across multiple columns (Multivariate analysis) and to build data products. \n",
    "\n",
    "Machine learning is:\n",
    "- Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention. (https://www.sas.com/en_us/insights/analytics/machine-learning.html#:~:text=Machine%20learning%20is%20a%20method,decisions%20with%20minimal%20human%20intervention.)\n",
    "- Machine learning (ML) is the study of computer algorithms that improve automatically through experience.[1] It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so.[2] Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks. (https://en.wikipedia.org/wiki/Machine_learning)\n",
    "\n",
    "Examples of data products could include:\n",
    "- A product recommender\n",
    "- A customer churn predictor\n",
    "- A mail labeler (Primary, promotion, social, spam, etc.)\n",
    "- Sentiment analyser for social media messages\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1204/1*qYoU2VTBsORAfhkfiluURQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will refer to the column that we are trying to calculate as the <b>target variable</b>. The columns used for this calculation will be refered to as the <b>feature variables</b>.\n",
    "\n",
    "For example, if we want to predict a person's shoe size based on their body length:\n",
    "- The shoe size is the target variable\n",
    "- The body length is the feature variable\n",
    "\n",
    "Extra info: The terms 'target' and 'feature' are borrowed from the field of Machine Learning. In the field of statistics, we refer to the target variable as the dependent variable and we refer to the feature variables as the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the target variable is a categorical variable then we refer to this task as a classification task.\n",
    "\n",
    "Examples of classification tasks:\n",
    "- Predict if a customer will churn. \n",
    "- Predict if a customer will use a specific product.\n",
    "- Label mails as spam.\n",
    "- Label financial transactions as fraudulent.\n",
    "- Label a social media message as positive, neutral or negative.\n",
    "- Predict if a customer of the bank will be able to pay back the loan.\n",
    "\n",
    "Examples of machine learning algorithms that we could use for classification:\n",
    "- Decision trees\n",
    "- Random forests\n",
    "- Logistic regression\n",
    "- Neural networks\n",
    "- Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = sns.load_dataset(\"iris\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1000/1*Hh53mOF4Xy4eORjLilKOwA.png \"Iris dataset\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features= ['sepal_length']\n",
    "dt = DecisionTreeClassifier(max_depth = 1) # Increase max_depth to see effect in the plot\n",
    "dt.fit(iris[features], iris['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`conda install -c anaconda graphviz`  \n",
    "`conda install -c anaconda python-graphviz`  \n",
    "`conda install -c anaconda pydot`  \n",
    "If the code below still does not work, install from here: (https://graphviz.org/download/)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6276\\954070010.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_tree_classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Generate plot data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "def plot_tree_classification(model, features, class_names):\n",
    "    # Generate plot data\n",
    "    dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                          feature_names=features,  \n",
    "                          class_names=class_names,  \n",
    "                          filled=True, rounded=True,  \n",
    "                          special_characters=True)  \n",
    "\n",
    "    # Turn into graph using graphviz\n",
    "    graph = graphviz.Source(dot_data)  \n",
    "\n",
    "    # Write out a pdf\n",
    "    graph.render(\"decision_tree\")\n",
    "\n",
    "    # Display in the notebook\n",
    "    return graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree_classification(dt, features, np.sort(iris.species.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dt.predict(iris[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, actuals):\n",
    "    if(len(predictions) != len(actuals)):\n",
    "        raise Exception(\"The amount of predictions did not equal the amount of actuals\")\n",
    "    \n",
    "    return (predictions == actuals).sum() / len(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_accuracy(predictions, iris.species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_train, iris_test = train_test_split(iris, test_size=0.3, random_state=42, stratify=iris['species'])\n",
    "print(iris_train.shape, iris_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= ['sepal_length', 'sepal_width']\n",
    "dt_classification = DecisionTreeClassifier(max_depth = 10) # Increase max_depth to see effect in the plot\n",
    "dt_classification.fit(iris_train[features], iris_train['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsOnTrainset = dt_classification.predict(iris_train[features])\n",
    "predictionsOnTestset = dt_classification.predict(iris_test[features])\n",
    "\n",
    "accuracyTrain = calculate_accuracy(predictionsOnTrainset, iris_train.species)\n",
    "accuracyTest = calculate_accuracy(predictionsOnTestset, iris_test.species)\n",
    "\n",
    "print(\"Accuracy on training set \" + str(accuracyTrain))\n",
    "print(\"Accuracy on test set \" + str(accuracyTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio assignment 15\n",
    "30 min: Train a decision tree to predict the species of a penguin based on their characteristics.\n",
    "- Split the penguin dataset into a train (70%) and test (30%) set.\n",
    "- Use the train set to fit a DecisionTreeClassifier. You are free to to choose which columns you want to use as feature variables and you are also free to choose the max_depth of the tree. \n",
    "<b>Note</b>: Some machine learning algorithms can not handle missing values. You will either need to \n",
    " - replace missing values (with the mean or most popular value). For replacing missing values you can use .fillna(\\<value\\>) https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html\n",
    " - remove rows with missing data.  You can remove rows with missing data with .dropna() https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "- Use your decision tree model to make predictions for both the train and test set.\n",
    "- Calculate the accuracy for both the train set predictions and test set predictions.\n",
    "- Is the accurracy different? Did you expect this difference?\n",
    "- Use the plot_tree_classification function above to create a plot of the decision tree. Take a few minutes to analyse the decision tree. Do you understand the tree?\n",
    "\n",
    "Optional: Perform the same tasks but try to predict the sex of the pinguin based on the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset(\"penguins\")\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/0v1CGNV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio assignment 16\n",
    "30 min: Train a decision tree to predict one of the categorical columns of your own dataset.\n",
    "- Split your dataset into a train (70%) and test (30%) set.\n",
    "- Use the train set to fit a DecisionTreeClassifier. You are free to to choose which columns you want to use as feature variables and you are also free to choose the max_depth of the tree. \n",
    "- Use your decision tree model to make predictions for both the train and test set.\n",
    "- Calculate the accuracy for both the train set predictions and test set predictions.\n",
    "- Is the accurracy different? Did you expect this difference?\n",
    "- Use the plot_tree function above to create a plot of the decision tree. Take a few minutes to analyse the decision tree. Do you understand the tree?\n",
    "    \n",
    "![](https://i.imgur.com/0v1CGNV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the target variable is a numerical variable then we refer to this task as a regression task.\n",
    "\n",
    "Examples of regression tasks:\n",
    "- Predict the price people are willing to pay for a house.\n",
    "- Predict the salary a student will earn in the future.\n",
    "\n",
    "Examples of machine learning algorithms that we could use for regression:\n",
    "- Decision trees\n",
    "- Random forests\n",
    "- Linear regression\n",
    "- Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.corr() # to find out which features correlate with sepal_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= ['petal_length'] # add 'petal_width' ('species' does not work; categorical is not implemented in DT of sciki learn)\n",
    "dt_regression = DecisionTreeRegressor(max_depth = 1) # Increase max_depth to see effect in the plot\n",
    "dt_regression.fit(iris_train[features], iris_train['sepal_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "def plot_tree_regression(model, features):\n",
    "    # Generate plot data\n",
    "    dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                          feature_names=features,  \n",
    "                          filled=True, rounded=True,  \n",
    "                          special_characters=True)  \n",
    "\n",
    "    # Turn into graph using graphviz\n",
    "    graph = graphviz.Source(dot_data)  \n",
    "\n",
    "    # Write out a pdf\n",
    "    graph.render(\"decision_tree\")\n",
    "\n",
    "    # Display in the notebook\n",
    "    return graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree_regression(dt_regression, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.aimlfront.com/images/rmse1.png \"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(predictions, actuals):\n",
    "    if(len(predictions) != len(actuals)):\n",
    "        raise Exception(\"The amount of predictions did not equal the amount of actuals\")\n",
    "    \n",
    "    return (((predictions - actuals) ** 2).sum() / len(actuals)) ** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsOnTrainset = dt_regression.predict(iris_train[features])\n",
    "predictionsOnTestset = dt_regression.predict(iris_test[features])\n",
    "\n",
    "rmseTrain = calculate_rmse(predictionsOnTrainset, iris_train.sepal_length)\n",
    "rmseTest = calculate_rmse(predictionsOnTestset, iris_test.sepal_length)\n",
    "\n",
    "print(\"RMSE on training set \" + str(rmseTrain))\n",
    "print(\"RMSE on test set \" + str(rmseTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio assignment 17\n",
    "30 min: Train a decision tree to predict the body_mass_g of a penguin based on their characteristics.\n",
    "- Split the penguin dataset into a train (70%) and test (30%) set.\n",
    "- Use the train set to fit a DecisionTreeRegressor. You are free to to choose which columns you want to use as feature variables and you are also free to choose the max_depth of the tree. \n",
    "<b>Note</b>: Some machine learning algorithms can not handle missing values. You will either need to \n",
    " - replace missing values (with the mean or most popular value). For replacing missing values you can use .fillna(\\<value\\>) https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html\n",
    " - remove rows with missing data.  You can remove rows with missing data with .dropna() https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "- Use your decision tree model to make predictions for both the train and test set.\n",
    "- Calculate the RMSE for both the train set predictions and test set predictions.\n",
    "- Is the RMSE different? Did you expect this difference?\n",
    "- Use the plot_tree_regression function above to create a plot of the decision tree. Take a few minutes to analyse the decision tree. Do you understand the tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset(\"penguins\")\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio assignment 18\n",
    "30 min: Train a decision tree to predict one of the numerical columns of your own dataset.\n",
    "- Split your dataset into a train (70%) and test (30%) set.\n",
    "- Use the train set to fit a DecisionTreeRegressor. You are free to to choose which columns you want to use as feature variables and you are also free to choose the max_depth of the tree. \n",
    "- Use your decision tree model to make predictions for both the train and test set.\n",
    "- Calculate the RMSE for both the train set predictions and test set predictions.\n",
    "- Is the accurracy different? Did you expect this difference?\n",
    "- Use the plot_tree function above to create a plot of the decision tree. Take a few minutes to analyse the decision tree. Do you understand the tree?\n",
    "    \n",
    "![](https://i.imgur.com/0v1CGNV.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
